{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "sample_n = 100\n",
    "trial_n = 3 # Number of JSON parsing attempts\n",
    "output_step = 10 # Number of attempts for step 5\n",
    "\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA_TYPE = \"UQA\"\n",
    "# QA_TYPE = \"RQA\"\n",
    "QA_TYPE = \"AQuA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input CSV path\n",
    "path_csv = Path(f\"../data/input/{QA_TYPE}.csv\")\n",
    "path_csv.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_id = \"question_id\"\n",
    "# col_evidence = \"evidence_wo_url\"\n",
    "# col_evidence = \"evidence\"\n",
    "col_evidence = \"rationale\"\n",
    "col_question = \"question\"\n",
    "# col_question = \"question_sentence\"\n",
    "# col_choices = \"choices\"\n",
    "col_choices = \"options\"\n",
    "# col_answer = \"answer\"\n",
    "col_answer = \"correct\"\n",
    "\n",
    "list_convert_cols = [col_choices]\n",
    "# list_convert_cols = [col_choices, col_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = \"gemma2:9b\"\n",
    "openai_model = \"gpt-4o-mini-2024-07-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output paths\n",
    "dir_output = Path(f\"../data/output/{QA_TYPE}_output_4/\")\n",
    "if not dir_output.exists():\n",
    "    dir_output.mkdir()\n",
    "\n",
    "output_path_qa = dir_output / f\"{QA_TYPE}_{ollama_model.replace(':', '_')}_{{trial_no}}.csv\"\n",
    "output_path_qa_tmp = dir_output / f\"{QA_TYPE}_{ollama_model.replace(':', '_')}_tmp.csv\" # 途中経過\n",
    "\n",
    "output_path_step1 = dir_output / f\"{QA_TYPE}_step1.csv\"\n",
    "output_path_step2 = dir_output / f\"{QA_TYPE}_step2.csv\"\n",
    "output_path_step2_use = dir_output / f\"{QA_TYPE}_step2_use.csv\"\n",
    "output_path_step4 = dir_output / f\"{QA_TYPE}_step4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parts of speech to be masked\n",
    "POS_CONTENT_WORD = ['PROPN', 'NOUN', 'VERB', 'ADJ', 'ADV', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mask_rate = list(range(0, 105, 5))\n",
    "print(list_mask_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP2_PROMPT = \"\"\"The following meta table contains metadata extracted from Text1, Text2, and Text3 according to the definition. Fill in the values for \"Part of Speech\", \"Category\", and \"Meaning\" in the table, and output the JSON in the format {{'data' : [ {{'word': str, 'part_of_speech': str, 'category': str, 'meaning': str}}, ...]}}.\n",
    "\n",
    "## Meta Table\n",
    "{step1_output}\n",
    "\n",
    "## Definition\n",
    "- Category: One of \"organization name, individual name, technical term\"\n",
    "- Meaning: Words that express higher-level concepts (multiple possible). Do not use other \"words\".\n",
    "\n",
    "## Example\n",
    "Word | Part of Speech | Category | Meaning\n",
    "---|---|---|---\n",
    "Medical Team | Common Noun | Organization Name | Healthcare\n",
    "Relay Station | Common Noun | Technical Term | Communication\n",
    "Tanaka Vehicles | Proper Noun | Organization Name | Company, Manufacturing\n",
    "Chronowar | Proper Noun | Technical Term | Product Name\n",
    "Napoleon | Proper Noun | Individual Name | Historical Figure\n",
    "\n",
    "## Text1\n",
    "{context_input}\n",
    "\n",
    "## Text2\n",
    "{q_input}\n",
    "\n",
    "## Text3\n",
    "{choices_input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP3_PROMPT = \"\"\"Change the numerical parts of Text1, Text2, and Text3 according to the following conditions. Output the response in the specified format.\n",
    "\n",
    "## Conditions\n",
    "- Increase the numerical values by 32%\n",
    "- Display numerical values to two decimal places\n",
    "- If there are no numerical values, return the text as is\n",
    "- Keep year and month values unchanged\n",
    "\n",
    "## Format\n",
    "- JSON\n",
    "- keys:\n",
    "    - conditions: list[str]\n",
    "        - List as \"<original number> -> <changed number>\"\n",
    "        - If no numbers were changed, use \"no change\"\n",
    "    - result: {{'text1': str, 'text2': str, 'text3': str}}\n",
    "        - Text after replacing the numerical values\n",
    "\n",
    "## Text1\n",
    "{context_input}\n",
    "\n",
    "## Text2\n",
    "{q_input}\n",
    "\n",
    "## Text3\n",
    "{choices_input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP5_PROMPT = \"\"\"The following is a text and metadata related to the code terms within the text. Answer the question concisely according to the instructions.\n",
    "\n",
    "## Instructions\n",
    "- Choose the answer from the options and respond with the corresponding number.\n",
    "- Respond in JSON format as {{'basis': str, 'answer': int}}\n",
    "- Use only the text as a reference for the basis\n",
    "\n",
    "## Text\n",
    "{context}\n",
    "\n",
    "## Metadata\n",
    "{metadata}\n",
    "\n",
    "## Question\n",
    "{question}\n",
    "\n",
    "## Options\n",
    "{option_list}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_async_client = AsyncOpenAI()\n",
    "ollama_client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = 'user'\n",
    "AI = 'assistant'\n",
    "SYS = 'system'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(client:OpenAI, model:str, messages:list[dict], stream:bool=True, output_json:bool=False):\n",
    "    param = {\n",
    "        'model':model,\n",
    "        'messages':messages,\n",
    "        'stream':stream\n",
    "    }\n",
    "    \n",
    "    if output_json:\n",
    "        param['response_format'] = {'type': 'json_object'}\n",
    "\n",
    "    return client.chat.completions.create(**param)\n",
    "\n",
    "def write_stream(stream) -> str:\n",
    "    ret = \"\"\n",
    "    for c in stream:\n",
    "        dlt = c.choices[0].delta.content\n",
    "        if dlt:\n",
    "            ret += dlt\n",
    "            print(dlt, end=\"\", flush=True)\n",
    "\n",
    "    return ret\n",
    "\n",
    "def append_message(role:str, content:str, messages:list[dict]=[]):\n",
    "    messages.append({'role': role, 'content': content})\n",
    "    return messages\n",
    "\n",
    "async def aget_response(client:AsyncOpenAI, model:str, messages:list[dict], output_json:bool=False) -> str:\n",
    "    param = {\n",
    "        'model':model,\n",
    "        'messages':messages\n",
    "    }\n",
    "    if output_json:\n",
    "        param['response_format'] = {'type': 'json_object'}\n",
    "\n",
    "    ret = await client.chat.completions.create(**param)\n",
    "    return ret.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(list_convert_cols) > 0:\n",
    "    param = {\n",
    "        'converters': {col:literal_eval for col in list_convert_cols}\n",
    "    }\n",
    "else:\n",
    "    param = {}\n",
    "\n",
    "df_qa = pd.read_csv(path_csv, **param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to sample_n\n",
    "if df_qa.shape[0] > sample_n:\n",
    "    print('filtering:', df_qa.shape[0], '->', sample_n)\n",
    "    df_qa = df_qa.sample(sample_n, random_state=seed).copy(deep=True)\n",
    "\n",
    "df_qa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step1\n",
    "- Extract words from `context`, `question`, and `choices`\n",
    "- Determine if it is a content word\n",
    "- Create the word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"merge_hyphenated\")\n",
    "def merge_hyphenated(doc):\n",
    "    \"\"\"Detect hyphenated words as a single word\"\"\"\n",
    "    spans = []\n",
    "    for i in range(len(doc) - 2):\n",
    "        if doc[i + 1].text == '-' and not doc[i + 1].whitespace_:\n",
    "            spans.append(doc[i:i+3])\n",
    "    filtered_spans = filter_spans(spans)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for span in filtered_spans:\n",
    "            retokenizer.merge(span)\n",
    "    return doc\n",
    "\n",
    "def get_entity_token_index(doc:spacy.tokens.doc.Doc, start_i:int) -> list[int]:\n",
    "    \"\"\"Search until the end of the entity token and return the index up to the end position\"\"\"\n",
    "    list_ind = [start_i]\n",
    "    if len(doc) <= (start_i+1):\n",
    "        return list_ind\n",
    "    \n",
    "    cur = start_i + 1\n",
    "    while cur < len(doc):\n",
    "        if doc[cur].ent_iob_ == \"O\":\n",
    "            return list_ind\n",
    "        \n",
    "        list_ind.append(cur)\n",
    "        cur += 1\n",
    "\n",
    "    return list_ind\n",
    "\n",
    "def process(nlp:spacy.language.Language, text:str) -> pd.DataFrame:\n",
    "    \"\"\"Output a list of morphemes from the text and return a dataframe of words (including duplicates)\"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    list_words = []\n",
    "    list_checked_i = []\n",
    "\n",
    "    for token in doc:\n",
    "        # entity token\n",
    "        if token.ent_type_:\n",
    "            # Start token of the entity\n",
    "            if token.ent_iob_ == \"B\":\n",
    "                tmp_index = get_entity_token_index(doc, token.i)\n",
    "                tmp_words = doc[tmp_index[0]:tmp_index[-1]+1].text\n",
    "                tmp_lemma = doc[tmp_index[0]:tmp_index[-1]+1].lemma_\n",
    "                list_words.append(\n",
    "                    {\n",
    "                        'word': tmp_words,\n",
    "                        'part_of_speech': token.pos_,\n",
    "                        'category': token.ent_type_, \n",
    "                        'lemma': tmp_lemma,\n",
    "                        'word_count': len(tmp_words.split()),\n",
    "                        'index': tmp_index\n",
    "                    }\n",
    "                )\n",
    "                list_checked_i.extend(tmp_index)\n",
    "        else:\n",
    "            word_data = {\n",
    "                    'word': token.text,\n",
    "                    'part_of_speech': token.pos_,\n",
    "                    'category': token.ent_type_,\n",
    "                    'lemma': token.lemma_,\n",
    "                    'word_count': len(token.text.split()),\n",
    "                    'index':[token.i]\n",
    "                }\n",
    "            \n",
    "            if token.i in list_checked_i:\n",
    "                continue\n",
    "            \n",
    "            if token.pos_ in ['PUNCT', 'SPACE']:\n",
    "                word_data['word_count'] = 0\n",
    "\n",
    "            list_words.append(\n",
    "                word_data\n",
    "            )\n",
    "            list_checked_i.append(token.i)\n",
    "\n",
    "    df = pd.DataFrame(list_words)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_content_word(text:str, pos:str, category:str) -> bool:\n",
    "    \"\"\"Return True if the text is a content word\"\"\"\n",
    "    if (category != \"\") or text.count(' ') > 0:\n",
    "        return True\n",
    "    \n",
    "    if pos in POS_CONTENT_WORD:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1(df_qa:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract morphemes from the text column of the QA\"\"\"\n",
    "    list_result = []\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.add_pipe(\"merge_hyphenated\", before='parser')\n",
    "\n",
    "    for col in [col_evidence, col_question, col_choices]:\n",
    "        if col == col_choices:\n",
    "            list_word_df = df_qa[col].apply(lambda x: pd.concat([process(nlp, choice) for choice in x]))\n",
    "        else:\n",
    "            list_word_df = df_qa[col].apply(lambda x: process(nlp, x))\n",
    "\n",
    "        for i, tmp in enumerate(list_word_df):\n",
    "            tmp[col_id] = df_qa.iloc[i][col_id]\n",
    "            tmp['mask_col'] = col\n",
    "\n",
    "        list_result.extend(list_word_df)\n",
    "    \n",
    "    df_result = pd.concat(list_result)\n",
    "\n",
    "    df_result['is_content_word'] = df_result.apply(lambda x: is_content_word(x['word'], x['part_of_speech'], x['category']), axis=1)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = step1(df_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove morphemes extracted from `options` (AQuA only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = df_word[df_word['mask_col']!=col_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = df_word[~df_word['category'].isin([\"CARDINAL\", \"DATE\", \"PERCENT\", \"ORDINAL\", \"QUANTITY\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step2\n",
    "- Generate category and meaning for each content word using `gemma 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_markdown(df:pd.DataFrame):\n",
    "    meta_table_s2 = ' | '.join(df.columns) + '\\n'\n",
    "    meta_table_s2 += ' | '.join(['---']*len(df.columns.to_list())) + \"\\n\"\n",
    "    meta_table_s2 += '\\n'.join(df.apply(lambda x: ' | '.join([x[col] for col in df.columns]), axis=1).values)\n",
    "\n",
    "    return meta_table_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2(client:OpenAI, model:str, df_qa:pd.DataFrame, df_word:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a word list at the lemma level from df_word and add category and meaning for content words\"\"\"\n",
    "    list_result = []\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.add_pipe(\"merge_hyphenated\", before='parser')\n",
    "\n",
    "    for i, row_qa in tqdm(list(df_qa.iterrows())):\n",
    "        qa_id = row_qa[col_id]\n",
    "        rows_word = df_word[(df_word[col_id]==qa_id) & df_word['is_content_word']]\n",
    "        \n",
    "        # Group by lemma\n",
    "        cols_unique = ['part_of_speech', 'category']\n",
    "        df_gr_lemma = rows_word.groupby('lemma').agg({col:'unique' for col in cols_unique}).reset_index().copy()\n",
    "        for col in cols_unique:\n",
    "            df_gr_lemma[col] = df_gr_lemma[col].apply(', '.join)\n",
    "        df_gr_lemma = df_gr_lemma.rename(columns={'lemma':'word'})\n",
    "        df_gr_lemma['meaning'] = \"\"\n",
    "        df_gr_lemma['word_lower'] = df_gr_lemma['word'].apply(lambda x: x.lower().strip(string.punctuation))# 紐づけ用\n",
    "\n",
    "        # Process 10 words at a time to avoid failure\n",
    "        for start in range(0, len(df_gr_lemma), 10):\n",
    "            end = start + 10\n",
    "            chunk = df_gr_lemma.iloc[start:end]\n",
    "\n",
    "            # Reprocess until the meaning is filled\n",
    "            total_output_count = chunk.shape[0]\n",
    "            list_tmp_result = []\n",
    "            chunk_count = 10 \n",
    "            while (total_output_count > 0) and (chunk_count > 0) :\n",
    "                print(qa_id, total_output_count, chunk['word'].unique())\n",
    "                md_metatable = convert_df_to_markdown(chunk.drop(columns='word_lower'))\n",
    "\n",
    "                messages = []\n",
    "                prompt = STEP2_PROMPT.format(\n",
    "                    step1_output=md_metatable, \n",
    "                    context_input=row_qa[col_evidence],\n",
    "                    q_input=row_qa[col_question],\n",
    "                    choices_input='\\n'.join(row_qa[col_choices]),\n",
    "                )\n",
    "                messages = append_message(USER, prompt, messages)\n",
    "                \n",
    "                # Generate\n",
    "                count = trial_n\n",
    "                chunk_count -= 1\n",
    "                while count > 0:\n",
    "                    try:\n",
    "                        response = generate(client, model, messages, stream=False, output_json=True).choices[0].message.content\n",
    "                        data_s2 = json.loads(response)['data']\n",
    "                        df_tmp = pd.DataFrame(data_s2)\n",
    "                        df_tmp[col_id] = qa_id\n",
    "\n",
    "                        # 1. Convert to lowercase and remove punctuation and join them\n",
    "                        df_tmp_1 = df_tmp.copy()\n",
    "                        df_tmp_1['word_lower'] = df_tmp_1['word'].apply(lambda x: x.lower().strip(string.punctuation)) # 紐づけ用\n",
    "                        df_tmp_1 = df_tmp_1[df_tmp_1['word_lower'].isin(chunk['word_lower'].unique())].copy()\n",
    "                        df_tmp_1 = df_tmp_1[(df_tmp_1['meaning'].notna())&(df_tmp_1['meaning']!='')]\n",
    "                        print(df_tmp_1['word'].unique())\n",
    "                        list_tmp_result.append(df_tmp_1.drop(columns='word_lower').copy())\n",
    "                        chunk = chunk[~chunk['word_lower'].isin(df_tmp_1['word_lower'].unique())]\n",
    "                        \n",
    "                        # 2. Convert the extracted words to lemmas and join them\n",
    "                        if chunk.shape[0] > 0:\n",
    "                            df_tmp_2 = df_tmp.loc[~df_tmp.index.isin(df_tmp_1.index.to_list())].copy()\n",
    "                            df_tmp_2['lemma_'] = df_tmp_2['word']\n",
    "                            for i, row in df_tmp_2.iterrows():\n",
    "                                doc = nlp(row['word'])\n",
    "                                df_tmp.loc[i, 'lemma_'] = doc[0:].lemma_\n",
    "\n",
    "                            # Join\n",
    "                            df_tmp_2 = df_tmp_2[df_tmp_2['lemma_'].isin(chunk['word'])]\n",
    "                            print(df_tmp_2['lemma_'].unique())\n",
    "                            list_tmp_result.append(df_tmp_2.drop(columns='lemma_').copy())\n",
    "                            chunk = chunk[~chunk['word'].isin(df_tmp_2['lemma_'].unique())]\n",
    "\n",
    "                        total_output_count = chunk.shape[0]\n",
    "                        break\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print('row', i, ': error', e)\n",
    "                        count -= 1\n",
    "                \n",
    "            list_result.extend(list_tmp_result)\n",
    "\n",
    "    return pd.concat(list_result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma = step2(ollama_client, ollama_model, df_qa, df_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_del_index = []\n",
    "list_concat_df = []\n",
    "if 'data' in df_lemma.columns:\n",
    "    rows = df_lemma[df_lemma['data'].notna()]\n",
    "    for i, row in rows.iterrows():\n",
    "        tmp_df = pd.DataFrame(row['data'])\n",
    "        tmp_df[col_id] = row[col_id]\n",
    "        list_del_index.append(i)\n",
    "        list_concat_df.append(tmp_df.copy())\n",
    "\n",
    "    df_lemma.drop(index=list_del_index, inplace=True)\n",
    "    df_lemma.drop(columns=['data'], inplace=True)\n",
    "    df_lemma = pd.concat([df_lemma] + list_concat_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word.to_csv(output_path_step1, encoding='utf-8-sig', index=False)\n",
    "df_lemma.to_csv(output_path_step2, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a word list for code conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_use = df_word[df_word['is_content_word']].copy()\n",
    "df_word_use['code'] = df_word_use.groupby([col_id, 'lemma']).ngroup()\n",
    "df_word_use['code'] = df_word_use.groupby(col_id)['code'].rank(method='dense').astype(int)\n",
    "df_word_use['code'] = df_word_use['code'].apply(lambda x: \"r\"+str(x).zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging process\n",
    "list_merge = []\n",
    "checked_index = []\n",
    "usecols = ['word', 'part_of_speech', 'category', 'lemma', 'word_count', 'index',\n",
    "       'question_id', 'mask_col', 'is_content_word', 'code',\n",
    "       'part_of_speech_output', 'category_output', 'meaning']\n",
    "# 1. Merge the lemma and word columns\n",
    "df_merge_tmp = df_word_use.merge(df_lemma.reset_index(), how='inner', left_on=[col_id, 'lemma'], right_on=[col_id, 'word'], suffixes=['', '_output'])\n",
    "list_merge.append(df_merge_tmp[usecols].fillna('').copy())\n",
    "df_lemma_tmp = df_lemma.loc[~df_lemma.index.isin(df_merge_tmp['index_output'])].copy()[df_lemma.columns]\n",
    "checked_index.extend(df_merge_tmp.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2. Convert all to lowercase and merge\n",
    "df_word_use_tmp = df_word_use[~df_word_use.index.isin(checked_index)].copy()\n",
    "df_word_use_tmp['word_lower'] = df_word_use_tmp['lemma'].apply(lambda x: x.lower().strip(string.punctuation))\n",
    "df_lemma_tmp['word_lower'] = df_lemma_tmp['word'].apply(lambda x: x.lower().strip(string.punctuation))\n",
    "df_merge_tmp = df_word_use_tmp.merge(df_lemma_tmp.drop(columns=['word']).reset_index(), how='inner', on=[col_id, 'word_lower'], suffixes=['', '_output'])\n",
    "list_merge.append(df_merge_tmp[usecols].fillna('').copy())\n",
    "df_lemma_tmp = df_lemma_tmp.loc[~df_lemma_tmp.index.isin(df_merge_tmp['index_output'])].copy()[df_lemma.columns]\n",
    "checked_index.extend(df_merge_tmp.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Reconvert the word in df_lemma to a lemma and merge\n",
    "df_word_use_tmp = df_word_use[~df_word_use.index.isin(checked_index)].copy()\n",
    "df_word_use_tmp['word_lower'] = df_word_use_tmp['lemma'].apply(lambda x: x.lower().strip(string.punctuation))\n",
    "df_lemma_tmp['lemma'] = None\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"merge_hyphenated\", before='parser')\n",
    "\n",
    "for i, row in df_lemma_tmp.iterrows():\n",
    "    doc = nlp(row['word'])\n",
    "    df_lemma_tmp.loc[i, 'lemma'] = doc[0:].lemma_\n",
    "\n",
    "df_lemma_tmp['word_lower'] = df_lemma_tmp['lemma'].apply(lambda x: x.lower().strip(string.punctuation))\n",
    "\n",
    "df_merge_tmp = df_word_use_tmp.merge(df_lemma_tmp.drop(columns=['word']).reset_index(), how='inner', on=[col_id, 'word_lower'], suffixes=['', '_output'])\n",
    "list_merge.append(df_merge_tmp[usecols].fillna('').copy())\n",
    "df_lemma_tmp = df_lemma_tmp.loc[~df_lemma_tmp.index.isin(df_merge_tmp['index_output'])].copy()[df_lemma.columns]\n",
    "checked_index.extend(df_merge_tmp.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_meaning = pd.concat(list_merge + [df_word_use.loc[~df_word_use.index.isin(checked_index)]], ignore_index=True)\n",
    "\n",
    "for col in ['part_of_speech', 'category']:\n",
    "    df_word_meaning[f\"{col}_new\"] = df_word_meaning[f'{col}']\n",
    "    df_word_meaning.loc[df_word_meaning[f\"{col}_new\"]==\"\", f\"{col}_new\"] = df_word_meaning[df_word_meaning[f\"{col}_new\"]==\"\"][f'{col}_output']\n",
    "\n",
    "df_word_new = df_word_meaning[['lemma', 'word', 'part_of_speech_new', 'category_new', 'meaning', col_id, 'code']].rename(columns=\n",
    "    {\n",
    "        'part_of_speech_new': 'part_of_speech',    \n",
    "        'category_new': 'category',    \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_new.to_csv(output_path_step2_use, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step3\n",
    "- Numeric conversion\n",
    "- Convert only `question` and `options`; do not convert `rationale`\n",
    "- Convert using code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def scale_numbers_in_text(text):\n",
    "    # Regular expression to find numbers (supports both integers and decimals)\n",
    "    def replace(match):\n",
    "        # Retrieve the matched number, scale it by 1.23, and round it to 2 decimal places\n",
    "        number = float(match.group())\n",
    "        scaled_number = round(number * 1.23, 2)\n",
    "        # Format as a string with 2 decimal places\n",
    "        return f\"{scaled_number:.2f}\"\n",
    "\n",
    "    # Use re.sub() to replace all numbers with their scaled values (1.23 times)\n",
    "    updated_text = re.sub(r'\\d+(?:\\.\\d+)?', replace, text)\n",
    "    return updated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3(client:OpenAI, model:str, df_qa:pd.DataFrame) -> pd.DataFrame:\n",
    "    df_qa['s3_output_context'] = df_qa[col_evidence]\n",
    "    df_qa['s3_output_Q'] = df_qa[col_question].apply(scale_numbers_in_text)\n",
    "    df_qa['s3_output_choices'] = df_qa[col_choices].apply(lambda x: [scale_numbers_in_text(i) for i in x])\n",
    "    df_qa['s3_conditions'] =  df_qa[col_evidence].apply(scale_numbers_in_text)\n",
    "\n",
    "    return df_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = step3(ollama_client, ollama_model, df_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa.to_csv(output_path_qa_tmp, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. regular masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step4\n",
    "- Select words to be coded based on the masking rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_mask_row(df_word:pd.DataFrame, mask_rate:int):\n",
    "    \"\"\"Select words to be coded based on the masking rate\"\"\"\n",
    "    assert (mask_rate >= 0) and (mask_rate <= 100), f\"`mask_rate` must be set between 0 and 100. mask_rate: {mask_rate}\"\n",
    "\n",
    "    df_copy = df_word.copy()\n",
    "    mask_col = f'p_{mask_rate}_masked'\n",
    "    df_copy[mask_col] = False\n",
    "\n",
    "    for qa_id, rows in df_copy.groupby(col_id):\n",
    "        list_lemma = rows['lemma'].unique().tolist()\n",
    "        mask_row_n = round(len(list_lemma) * (mask_rate/100))\n",
    "        print(f'ID_{qa_id} {mask_rate}% number of words to be masked:', mask_row_n)\n",
    "\n",
    "        list_mask_lemma = random.sample(list_lemma, k=mask_row_n)\n",
    "        mask_rows_index = rows[rows['lemma'].isin(list_mask_lemma)].index.values\n",
    "\n",
    "        df_copy.loc[mask_rows_index, mask_col] = True\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask_rate in list_mask_rate:\n",
    "    df_word_new = select_mask_row(df_word_new, mask_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4(df_qa:pd.DataFrame, list_mask_rate:list[int], df_word_new:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add masked text based on the masking rate to df_qa\"\"\"\n",
    "    df_copy = df_qa.copy()\n",
    "    for mask_rate in list_mask_rate:\n",
    "        df_copy[f's4_prg_encode_context_{mask_rate}'] = \"\"\n",
    "        df_copy[f's4_prg_encode_Q_{mask_rate}'] = \"\"\n",
    "        # Use `s3_output_choices` for `Choices` only this time\n",
    "        df_copy[f's4_prg_encode_choices_{mask_rate}'] = df_copy['s3_output_choices']\n",
    "\n",
    "        for i, row in df_copy.iterrows():\n",
    "            qa_id = row[col_id]\n",
    "            values = df_word_new[(df_word_new[col_id]==qa_id) & (df_word_new[f'p_{mask_rate}_masked'])].apply(lambda x: {x['code']:x['word']}, axis=1)\n",
    "            values = sorted(values, key=lambda x: x[next(iter(x))].count(' '), reverse=True)\n",
    "            \n",
    "            # for col in ['s3_output_context', 's3_output_Q', 's3_output_choices']:\n",
    "            for col in ['s3_output_context', 's3_output_Q']:\n",
    "                sub_text = row[col]\n",
    "                for pair in values:\n",
    "                    code = list(pair.keys())[0]\n",
    "                    word = list(pair.values())[0]\n",
    "                    sub_text = sub_text.replace(word, f\"<{code}>\")\n",
    "                df_copy.loc[i, col.replace('s3_output_', 's4_prg_encode_')+f\"_{mask_rate}\"] = sub_text\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = step4(df_qa, list_mask_rate, df_word_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa.to_csv(output_path_qa_tmp, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_new.to_csv(output_path_step4, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_new = pd.read_csv(output_path_step4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the missing rate of meanings for each masking rate\n",
    "list_tmp = []\n",
    "for mask_rate in list_mask_rate:\n",
    "    if mask_rate == 0:\n",
    "        continue\n",
    "    \n",
    "    tmp_total_lemma = df_word_new[df_word_new[f'p_{mask_rate}_masked']]['lemma'].nunique()\n",
    "    tmp_empty_meaning_lemma = tmp_total_lemma - df_word_new[df_word_new[f'p_{mask_rate}_masked'] & df_word_new['meaning'].notna()]['lemma'].nunique()\n",
    "    list_tmp.append({'MR': mask_rate, 'number of words with missing meanings': tmp_empty_meaning_lemma, 'word count': tmp_total_lemma, 'missing rate of meanings': tmp_empty_meaning_lemma / tmp_total_lemma})\n",
    "    \n",
    "pd.DataFrame(list_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step5\n",
    "- generate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def exec_step5(client:AsyncOpenAI, model:str, i:int, output_col:str, query_col:str, context:str, question:str, choices: list, metadata: str, count:int):\n",
    "    messages = []\n",
    "    prompt = STEP5_PROMPT.format(\n",
    "        context=context,\n",
    "        metadata=metadata,\n",
    "        question=question,\n",
    "        option_list=[f\"{i}. {val}\" for i, val in enumerate(choices, 1)]\n",
    "    )\n",
    "    messages = append_message(USER, prompt, messages)\n",
    "    \n",
    "    while count > 0:\n",
    "        try:\n",
    "            res = await aget_response(client, model, messages, output_json=True)\n",
    "            ret = (i, json.loads(res)['answer'], prompt, output_col, query_col)\n",
    "            return ret\n",
    "\n",
    "        except Exception as e:\n",
    "            print('error', e)\n",
    "            count -= 1\n",
    "\n",
    "    return (i, '-1', '', output_col, query_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def step5(aclient:AsyncOpenAI, model:str, df_qa:pd.DataFrame, df_word_new:pd.DataFrame) -> pd.DataFrame:\n",
    "    df_copy = df_qa.copy()\n",
    "    print('model:', model)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for mask_rate in list_mask_rate:\n",
    "        tasks = []\n",
    "\n",
    "        output_col = f'answer_{model}_{mask_rate}'\n",
    "        query_col = f'query_{mask_rate}'\n",
    "        df_copy[output_col] = \"\"\n",
    "        df_copy[query_col] = \"\"\n",
    "\n",
    "        col_context = f's4_prg_encode_context_{mask_rate}'\n",
    "        col_Q = f's4_prg_encode_Q_{mask_rate}'\n",
    "        col_choices_tmp = f's4_prg_encode_choices_{mask_rate}'\n",
    "        \n",
    "        for i, row in df_copy.iterrows():\n",
    "            qa_id = row[col_id]\n",
    "\n",
    "            meta_table = df_word_new[(df_word_new[col_id]==qa_id) & (df_word_new[f'p_{mask_rate}_masked'])].groupby('lemma').agg(\n",
    "                {col: 'unique' for col in ['part_of_speech', 'category', 'meaning', 'code']}\n",
    "            ).copy()\n",
    "            if not meta_table.empty:\n",
    "                for col in ['part_of_speech', 'category', 'meaning', 'code']:\n",
    "                    meta_table[col] = meta_table[col].apply(lambda x: ', '.join(t for t in x if type(t)==str))\n",
    "            md_metatable = convert_df_to_markdown(meta_table)\n",
    "            count = trial_n\n",
    "            tasks.append(asyncio.ensure_future(exec_step5(aclient, model, i, output_col, query_col, row[col_context], row[col_Q], row[col_choices_tmp], md_metatable, count)))\n",
    "\n",
    "        results.extend(await asyncio.gather(*tasks))\n",
    "\n",
    "    for i, ans, query, output_col, query_col in results:\n",
    "        df_copy.loc[i, output_col] = ans\n",
    "        df_copy.loc[i, query_col] = query\n",
    "\n",
    "    return df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_num in range(1, output_step+1):\n",
    "    print('trial:', output_num) \n",
    "    df_result = await step5(openai_async_client, openai_model, df_qa, df_word_new)\n",
    "    save_path_tmp = str(output_path_qa).format(trial_no=output_num)\n",
    "    print(save_path_tmp)\n",
    "    df_result.to_csv(save_path_tmp, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. partial lifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {   \n",
    "    'converters': {col:literal_eval for col in list_convert_cols + ['s3_output_choices']}\n",
    "}\n",
    "df_qa = pd.read_csv(output_path_qa_tmp, **param).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_new_all_meaning = df_word_new[df_word_new['meaning'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_all_meaning = step4(df_qa, list_mask_rate, df_word_new_all_meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tmp = []\n",
    "for mask_rate in list_mask_rate:\n",
    "    if mask_rate == 0:\n",
    "        continue\n",
    "\n",
    "    tmp_total_lemma = df_word_new_all_meaning[df_word_new_all_meaning[f'p_{mask_rate}_masked']]['lemma'].nunique()\n",
    "    tmp_empty_meaning_lemma = tmp_total_lemma - df_word_new_all_meaning[df_word_new_all_meaning[f'p_{mask_rate}_masked'] & df_word_new_all_meaning['meaning'].notna()]['lemma'].nunique()\n",
    "    list_tmp.append({'MR': mask_rate, 'number of words with missing meanings': tmp_empty_meaning_lemma, 'word count': tmp_total_lemma, 'missing rate of meanings': tmp_empty_meaning_lemma / tmp_total_lemma})\n",
    "\n",
    "pd.DataFrame(list_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_num in range(1, output_step+1):\n",
    "    print('trial:', output_num) \n",
    "    df_result = await step5(openai_async_client, openai_model, df_qa_all_meaning, df_word_new_all_meaning)\n",
    "    save_path_tmp = str(output_path_qa).format(trial_no=f\"{output_num}_filtered\")\n",
    "    print(save_path_tmp)\n",
    "    df_result.to_csv(save_path_tmp, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. strict masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {   \n",
    "    'converters': {col:literal_eval for col in list_convert_cols + ['s3_output_choices']}\n",
    "}\n",
    "df_qa_no_meaning = pd.read_csv(output_path_qa_tmp, **param).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_new_no_meaning = pd.read_csv(output_path_step4)\n",
    "df_word_new_no_meaning['meaning'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_no_meaning = step4(df_qa_no_meaning, list_mask_rate, df_word_new_no_meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tmp = []\n",
    "for mask_rate in list_mask_rate:\n",
    "    if mask_rate == 0:\n",
    "        continue\n",
    "    \n",
    "    tmp_total_lemma = df_word_new_no_meaning[df_word_new_no_meaning[f'p_{mask_rate}_masked']]['lemma'].nunique()\n",
    "    tmp_empty_meaning_lemma = tmp_total_lemma - df_word_new_no_meaning[df_word_new_no_meaning[f'p_{mask_rate}_masked'] & df_word_new_no_meaning['meaning'].notna()]['lemma'].nunique()\n",
    "    list_tmp.append({'MR': mask_rate, 'number of words with missing meanings': tmp_empty_meaning_lemma, 'word count': tmp_total_lemma, 'missing rate of meanings': tmp_empty_meaning_lemma / tmp_total_lemma})\n",
    "    \n",
    "pd.DataFrame(list_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_num in range(1, output_step+1):\n",
    "    print('trial:', output_num) \n",
    "    df_result = await step5(openai_async_client, openai_model, df_qa_no_meaning, df_word_new_no_meaning)\n",
    "    save_path_tmp = str(output_path_qa).format(trial_no=f\"{output_num}_no_meaning\")\n",
    "    print(save_path_tmp)\n",
    "    df_result.to_csv(save_path_tmp, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. lenient masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {   \n",
    "    'converters': {col:literal_eval for col in list_convert_cols + ['s3_output_choices']}\n",
    "}\n",
    "df_qa_no_verb = pd.read_csv(output_path_qa_tmp, **param).fillna(\"\")\n",
    "df_word_new_no_verb = pd.read_csv(output_path_step4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_lemma = df_word_new_no_verb.groupby([col_id, 'lemma'])['part_of_speech'].apply('unique').reset_index()\n",
    "unique_lemma['contains_verb'] = unique_lemma['part_of_speech'].apply(lambda x: 'verb' in [pos.lower() for pos in x if pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_new_no_verb = df_word_new_no_verb.merge(unique_lemma.rename(columns={'part_of_speech': 'POS_unique'}), how='left', on=[col_id, 'lemma'])\n",
    "df_word_new_no_verb.loc[df_word_new_no_verb['contains_verb'], [f'p_{mr}_masked' for mr in list_mask_rate]] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_no_verb = step4(df_qa_no_verb, list_mask_rate, df_word_new_no_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tmp = []\n",
    "for mask_rate in list_mask_rate:\n",
    "    if mask_rate == 0:\n",
    "        continue\n",
    "    \n",
    "    tmp_total_lemma = df_word_new_no_verb[df_word_new_no_verb[f'p_{mask_rate}_masked']]['lemma'].nunique()\n",
    "    tmp_empty_meaning_lemma = tmp_total_lemma - df_word_new_no_verb[df_word_new_no_verb[f'p_{mask_rate}_masked'] & df_word_new_no_verb['meaning'].notna()]['lemma'].nunique()\n",
    "    list_tmp.append({'MR': mask_rate, 'number of words with missing meanings': tmp_empty_meaning_lemma, 'word count': tmp_total_lemma, 'missing rate of meanings': tmp_empty_meaning_lemma / tmp_total_lemma})\n",
    "    \n",
    "pd.DataFrame(list_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_num in range(1, output_step+1):\n",
    "    print('trial:', output_num) \n",
    "    df_result = await step5(openai_async_client, openai_model, df_qa_no_verb, df_word_new_no_verb)\n",
    "    save_path_tmp = str(output_path_qa).format(trial_no=f\"{output_num}_no_verb\")\n",
    "    print(save_path_tmp)\n",
    "    df_result.to_csv(save_path_tmp, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
